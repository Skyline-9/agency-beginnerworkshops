{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 6: An Exercise in Learning XOR\n",
    "\n",
    "In this workshop, we will be working with PyTorch to create an XOR classifier? What exactly is XOR? Perhaps an example will help. \n",
    "\n",
    "![XOR](../assets/XOR.png)\n",
    "\n",
    "Essentially, we have a function on two features $f(a, b)$. Our features $a$ and $b$ can belong in two categories, either 0 or 1 in this case. In this example, XOR outputs 1 if either feature is in category 1, but not both. Otherwise, it outputs 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset\n",
    "First, we will need to create a dataset to solve a general XOR-like problem. We need to answer two questions. \n",
    "\n",
    "1) What kind of features / categories should our inputs have? \n",
    "2) What should our output space look like?\n",
    "\n",
    "We're working just with numbers. Theoretically, this shouldn't make too much difference. Practically, since we are working with numbers, some decisions might make it easier to train our network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.samples = \n",
    "\n",
    "        self.labels = \n",
    "\n",
    "    def __len__(self):\n",
    "        return \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click for code snippet of potential solution\n",
    "<details>\n",
    "\n",
    "class BinaryDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "    \n",
    "        self.samples - F.normalize(\n",
    "            torch.stack(\n",
    "                torch.Tensor([1, 1]),\n",
    "                torch.Tensor([2, 1]),\n",
    "                torch.Tensor([1, 2]),\n",
    "                torch.Tensor([1, 5]),\n",
    "                torch.Tensor([0.01, 1]),\n",
    "                torch.Tensor([5, 1]),\n",
    "                torch.Tensor([1, 0.01]),\n",
    "                torch.Tensor([-1, -1]),\n",
    "                torch.Tensor([-2, -1]),\n",
    "                torch.Tensor([-1, -2]),\n",
    "                torch.Tensor([-1, -5]),\n",
    "                torch.Tensor([-5, -1]),\n",
    "                torch.Tensor([1, -1]),\n",
    "                torch.Tensor([2, -1]),\n",
    "                torch.Tensor([1, -2]),\n",
    "                torch.Tensor([1, -5]),\n",
    "                torch.Tensor([0.01, -1]),\n",
    "                torch.Tensor([5, -1]),\n",
    "                torch.Tensor([-1, 1]),\n",
    "                torch.Tensor([-2, 1]),\n",
    "                torch.Tensor([-1, 2]),\n",
    "                torch.Tensor([-1, 5]),\n",
    "                torch.Tensor([-5, 1]),\n",
    "                torch.Tensor([-1, 0.01])\n",
    "        ))\n",
    "\n",
    "        self.labels = torch.cat((\n",
    "            torch.tile(torch.Tensor([1]), (12, 1)),\n",
    "            torch.tile(torch.Tensor([-1]), (12, 1)),\n",
    "        ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.samples[idx], self.labels[idx])\n",
    "\n",
    "<details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Our Model\n",
    "\n",
    "What kind of model can solve this problem? Does the number of layers matter? What activation should we choose? \n",
    "\n",
    "The number of layers ends up being very important for this problem. Let's create two networks to experiment with this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLinearModel_Singlelayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = torch.tanh(self.linear1(input))\n",
    "\n",
    "class BasicLinearModel_Multilayer(nn.Module):\n",
    "    def __init__(self, in_features, hidden_nodes, out_features):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_features, hidden_nodes)\n",
    "        self.linear2 = nn.Linear(hidden_nodes, out_features)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = torch.tanh(self.linear1(input))\n",
    "        return torch.tanh(self.linear2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    \n",
    "    class BasicLinearModel_Singlelayer(nn.Module):\n",
    "        def __init__(self, in_features, out_features):\n",
    "            super().__init__()\n",
    "            self.linear1 = nn.Linear(in_features, out_features)\n",
    "\n",
    "        def forward(self, input):\n",
    "            x = torch.tanh(self.linear1(input))\n",
    "\n",
    "    class BasicLinearModel_Multilayer(nn.Module):\n",
    "        def __init__(self, in_features, hidden_nodes, out_features):\n",
    "            super().__init__()\n",
    "            self.linear1 = nn.Linear(in_features, hidden_nodes)\n",
    "            self.linear2 = nn.Linear(hidden_nodes, out_features)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = torch.tanh(self.linear1(input))\n",
    "        return torch.tanh(self.linear2(x))\n",
    "        \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Utilities\n",
    "\n",
    "We will need some additional tools before we start training to evaluate our model. First, our network will likely have a continuous output range, decided by our activation function. Let's **binarize** this output to match the constraints we want to set on our learned XOR function. \n",
    "\n",
    "We'll also want to write a function to test the accuracy of our network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_pred(pred):\n",
    "    return torch.where(pred > 0, torch.Tensor([1]), torch.Tensor([-1]))\n",
    "\n",
    "def accuracy(pred, label):\n",
    "    pred = binary_pred(pred)\n",
    "\n",
    "    correct_results_sum = (pred == label).sum().float()\n",
    "    acc = correct_results_sum / pred.shape[0]\n",
    "    acc = torch.round(acc * 100).item()\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Let's take a typical training loop and apply it to our problem. We will also add some extra code to save **checkpoints** of our model every epoch, so we can load the weights at that point and see what our network has learned so far. \n",
    "\n",
    "We'll also add in a function to load our checkpoints easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, model, criterion, optimizer, savename):\n",
    "    for epoch in range(100):\n",
    "        \n",
    "        loss_history = []\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics every epoch\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        average_loss = loss.item()\n",
    "        if epoch % 10 == 0:\n",
    "            print('[Epoch %d] loss: %.5f' % (epoch + 1, average_loss))\n",
    "        loss_history.append(average_loss)\n",
    "        \n",
    "        filename = \"-\".join([savename, str(epoch) + \".pt\"])\n",
    "        if not os.path.isdir(\"./tmpdir\"):\n",
    "            os.mkdir(\"tmpdir\")\n",
    "        PATH = os.path.join(\"tmpdir\", filename)\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        \n",
    "    print('Finished Training')\n",
    "    return loss_history\n",
    "\n",
    "def load_checkpoint(model, savename, epoch):\n",
    "    checkpoint_name = \"-\".join([savename, str(epoch) + \".pt\"])\n",
    "    checkpoint = torch.load(os.path.join(\"tmpdir\", checkpoint_name))\n",
    "    model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BinaryDataset()\n",
    "model = BasicLinearModel_Multilayer(2, 2, 1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "trainloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "loss = train(trainloader, model, criterion, optimizer, 'multinet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our Model\n",
    "\n",
    "Let's write a quick utility that will create a bunch of random data points, and an explicit function to calculate the right answer, in order to test our network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = F.normalize(torch.rand(10, 2) * 2 - 1, dim=1)\n",
    "mask = torch.logical_xor(testset[:, 0] > 0, testset[:, 1] > 0)\n",
    "testlabels = torch.where(mask, torch.Tensor([1]), torch.Tensor([-1])).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Our Model\n",
    "\n",
    "Let's define a utility to look at the **decision boundary** for the model we just trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_decision_boundary(model, h=0.01):\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "\n",
    "    plt.axis('scaled')\n",
    "\n",
    "    plt.xlim(-1.1, 1.1)\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "\n",
    "    colors = {\n",
    "        -1: \"ro\", \n",
    "        1: \"go\"\n",
    "    }\n",
    "\n",
    "    trainloader = DataLoader(dataset, batch_size=1)\n",
    "    for data in trainloader:\n",
    "        inputs, label = data\n",
    "        plt.plot(\n",
    "            [inputs[0, 0]],\n",
    "            [inputs[0, 1]],\n",
    "            colors[int(label)],\n",
    "            markersize=20\n",
    "        )\n",
    "\n",
    "    x_range = np.arange(-1.1, 1.1, h)\n",
    "    y_range = np.arange(-1.1, 1.1, h)\n",
    "\n",
    "    xx, yy = np.meshgrid(x_range, y_range, indexing='ij')\n",
    "    Z = np.array([[binary_pred(model(torch.Tensor([x, y]).unsqueeze(0))) for x in x_range] for y in y_range])\n",
    "\n",
    "    plt.contourf(xx, yy, Z, colors=['red', 'green', 'green', 'green'], alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet = BasicLinearModel_Multilayer(2, 2, 1)\n",
    "load_checkpoint(mynet, \"multinet\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(mynet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
